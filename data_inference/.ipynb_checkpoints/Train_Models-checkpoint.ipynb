{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:31:39.132052Z",
     "start_time": "2024-11-08T10:31:39.114724Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:31:42.736310Z",
     "start_time": "2024-11-08T10:31:39.134754Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling1D, MaxPooling1D, Concatenate\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Dropout, BatchNormalization, LeakyReLU, ELU\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:31:42.786490Z",
     "start_time": "2024-11-08T10:31:42.738784Z"
    }
   },
   "outputs": [],
   "source": [
    "n_tips = ['674', '489', '87']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:31:44.582988Z",
     "start_time": "2024-11-08T10:31:42.788623Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle_base = '/workspace/coniferas(1)/data_inference/pickles/simulations_no_fossil/dataset_'\n",
    "data = dict()\n",
    "for i in n_tips:\n",
    "    with open(pickle_base + i + \"_10k.pkl\", 'rb') as f:\n",
    "        data[i] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:31:44.645740Z",
     "start_time": "2024-11-08T10:31:44.585112Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_nn(n_out, n_tips, clas=False, div_scenario = None):\n",
    "    input_data = Input(shape=(n_tips, 1))\n",
    "\n",
    "    final_filters = 128\n",
    "    x = Conv1D(16, kernel_size=3, padding='same')(input_data)\n",
    "    x = ELU()(x)\n",
    "    x = Conv1D(16, kernel_size=3, padding='same')(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    if n_tips > 256:\n",
    "        final_filters = 64\n",
    "        x = Conv1D(32, kernel_size=3, padding='same')(x)\n",
    "        x = ELU()(x)\n",
    "        x = Conv1D(32, kernel_size=3, padding='same')(x)\n",
    "        x = ELU()(x)\n",
    "        x = MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "        if n_tips > 512:\n",
    "            final_filters = 128\n",
    "            x = Conv1D(64, kernel_size=3, padding='same')(x)\n",
    "            x = ELU()(x)\n",
    "            x = Conv1D(64, kernel_size=3, padding='same')(x)\n",
    "            x = ELU()(x)\n",
    "            x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    x = Conv1D(final_filters, kernel_size=3, padding='same')(x)\n",
    "    x = ELU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x = Dense(32)(x)\n",
    "    x = ELU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Dense(n_out)(x)\n",
    "    if clas:\n",
    "        output_class = Softmax()(x)\n",
    "        \n",
    "    else:\n",
    "        if div_scenario != \"SAT\":\n",
    "            out_list = []\n",
    "\n",
    "            for i in range(n_out):\n",
    "                y = Dense(32)(x)\n",
    "                y = ELU()(y)\n",
    "                y = Dropout(0.3)(y)\n",
    "\n",
    "                y = Dense(1)(y)\n",
    "                y = LeakyReLU(alpha=10)(y)\n",
    "                out_list.append(y)\n",
    "\n",
    "            output_class = Concatenate()(out_list)\n",
    "            \n",
    "        elif div_scenario == \"WW\":\n",
    "            out_list = []\n",
    "\n",
    "            for i in range(n_out):\n",
    "                y = Dense(32)(x)\n",
    "                y = ELU()(y)\n",
    "                y = Dropout(0.3)(y)\n",
    "\n",
    "                y = Dense(1)(y)\n",
    "                y = Linear(y)\n",
    "                out_list.append(y)\n",
    "\n",
    "            output_class = Concatenate()(out_list)                \n",
    "            \n",
    "        else:\n",
    "            x = Dense(32)(x)\n",
    "            x = ELU()(x)\n",
    "            x = Dropout(0.3)(x)\n",
    "            x = Dense(1)(x)\n",
    "            output_class = LeakyReLU(alpha=10)(x)\n",
    "            \n",
    "    return Model(input_data, output_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:31:44.696275Z",
     "start_time": "2024-11-08T10:31:44.647803Z"
    }
   },
   "outputs": [],
   "source": [
    "callback = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "out_folder_path = \"/workspace/coniferas(1)/data_inference/models/\"\n",
    "os.makedirs(out_folder_path + 'class/', exist_ok=True)\n",
    "os.makedirs(out_folder_path + 'reg/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T11:39:05.924455Z",
     "start_time": "2024-11-08T10:31:44.699586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clasification training 674 tips\n",
      "Elapsed time 913.5207743644714\n",
      "\n",
      "Clasification training 489 tips\n",
      "Elapsed time 1722.0513048171997\n",
      "\n",
      "Clasification training 87 tips\n",
      "Elapsed time 1402.9934368133545\n"
     ]
    }
   ],
   "source": [
    "for i in n_tips:\n",
    "    print(\"\\nClasification training\", i, 'tips')\n",
    "\n",
    "    nn_model = create_nn(len(data[i]['y_class_train'][0]),\n",
    "                         int(i), clas=True)\n",
    "    nn_model.compile(loss=\"categorical_crossentropy\",\n",
    "                     optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "\n",
    "    start = time()\n",
    "    history = nn_model.fit(data[i]['X_train'], data[i]['y_class_train'],\n",
    "                           batch_size=128, epochs=1000, validation_split=0.1,\n",
    "                           callbacks=[callback], verbose=0)\n",
    "    elapsed_time = time()-start\n",
    "    print('Elapsed time', elapsed_time)\n",
    "\n",
    "    save_path = out_folder_path + 'class/' + i + \"_classification_\"\n",
    "\n",
    "    nn_model.save(save_path + \"model.keras\")\n",
    "    with open(save_path + \"history.pkl\", 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "    with open(save_path + \"model_data.pkl\", 'wb') as f:\n",
    "            pickle.dump([nn_model.count_params(), elapsed_time], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T17:24:26.780990Z",
     "start_time": "2024-11-08T16:04:39.732353Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression training 674 tips, BD model, _norm norm\n",
      "Elapsed time 72.86232209205627\n",
      "\n",
      "Regression training 674 tips, BD model,  norm\n",
      "Elapsed time 65.01599049568176\n",
      "\n",
      "Regression training 674 tips, HE model, _norm norm\n",
      "Elapsed time 82.6969530582428\n",
      "\n",
      "Regression training 674 tips, HE model,  norm\n",
      "Elapsed time 58.69716143608093\n",
      "\n",
      "Regression training 674 tips, ME model, _norm norm\n",
      "Elapsed time 84.64487767219543\n",
      "\n",
      "Regression training 674 tips, ME model,  norm\n",
      "Elapsed time 90.6526095867157\n",
      "\n",
      "Regression training 674 tips, SAT model, _norm norm\n",
      "Elapsed time 71.70607733726501\n",
      "\n",
      "Regression training 674 tips, SAT model,  norm\n",
      "Elapsed time 53.84978413581848\n",
      "\n",
      "Regression training 674 tips, SR model, _norm norm\n",
      "Elapsed time 81.4151291847229\n",
      "\n",
      "Regression training 674 tips, SR model,  norm\n",
      "Elapsed time 96.70000576972961\n",
      "\n",
      "Regression training 674 tips, WW model, _norm norm\n",
      "Elapsed time 94.1911301612854\n",
      "\n",
      "Regression training 674 tips, WW model,  norm\n",
      "Elapsed time 121.00370073318481\n",
      "\n",
      "Regression training 489 tips, BD model, _norm norm\n",
      "Elapsed time 124.42869544029236\n",
      "\n",
      "Regression training 489 tips, BD model,  norm\n",
      "Elapsed time 108.58923149108887\n",
      "\n",
      "Regression training 489 tips, HE model, _norm norm\n",
      "Elapsed time 147.48996424674988\n",
      "\n",
      "Regression training 489 tips, HE model,  norm\n",
      "Elapsed time 111.56327271461487\n",
      "\n",
      "Regression training 489 tips, ME model, _norm norm\n",
      "Elapsed time 144.60321927070618\n",
      "\n",
      "Regression training 489 tips, ME model,  norm\n",
      "Elapsed time 204.01095628738403\n",
      "\n",
      "Regression training 489 tips, SAT model, _norm norm\n",
      "Elapsed time 127.91743063926697\n",
      "\n",
      "Regression training 489 tips, SAT model,  norm\n",
      "Elapsed time 106.88540458679199\n",
      "\n",
      "Regression training 489 tips, SR model, _norm norm\n",
      "Elapsed time 136.8222119808197\n",
      "\n",
      "Regression training 489 tips, SR model,  norm\n",
      "Elapsed time 149.04193115234375\n",
      "\n",
      "Regression training 489 tips, WW model, _norm norm\n",
      "Elapsed time 200.3418207168579\n",
      "\n",
      "Regression training 489 tips, WW model,  norm\n",
      "Elapsed time 196.44902563095093\n",
      "\n",
      "Regression training 87 tips, BD model, _norm norm\n",
      "Elapsed time 63.520639419555664\n",
      "\n",
      "Regression training 87 tips, BD model,  norm\n",
      "Elapsed time 151.33463072776794\n",
      "\n",
      "Regression training 87 tips, HE model, _norm norm\n",
      "Elapsed time 195.65185356140137\n",
      "\n",
      "Regression training 87 tips, HE model,  norm\n",
      "Elapsed time 161.28179812431335\n",
      "\n",
      "Regression training 87 tips, ME model, _norm norm\n",
      "Elapsed time 204.05623817443848\n",
      "\n",
      "Regression training 87 tips, ME model,  norm\n",
      "Elapsed time 187.2709059715271\n",
      "\n",
      "Regression training 87 tips, SAT model, _norm norm\n",
      "Elapsed time 92.62034940719604\n",
      "\n",
      "Regression training 87 tips, SAT model,  norm\n",
      "Elapsed time 159.24970650672913\n",
      "\n",
      "Regression training 87 tips, SR model, _norm norm\n",
      "Elapsed time 235.35377144813538\n",
      "\n",
      "Regression training 87 tips, SR model,  norm\n",
      "Elapsed time 133.32786893844604\n",
      "\n",
      "Regression training 87 tips, WW model, _norm norm\n",
      "Elapsed time 177.64749121665955\n",
      "\n",
      "Regression training 87 tips, WW model,  norm\n",
      "Elapsed time 278.6980650424957\n"
     ]
    }
   ],
   "source": [
    "for i in n_tips:\n",
    "    for label in np.unique(data[i]['div_info_train']):\n",
    "        div_scenario = label.split('/')[1].split('_')[0]\n",
    "        \n",
    "        for data_norm in ['_norm', '']:\n",
    "            # Get regression values of the corresponding scenario\n",
    "            X_train = data[i]['X_train'][data[i]['div_info_train'] == label]\n",
    "            y_reg_train = data[i]['y_reg' + data_norm + '_train'][data[i]['div_info_train'] == label]\n",
    "            y_reg_train = [np.array(elem) for elem in y_reg_train]\n",
    "            \n",
    "            print(\"\\nRegression training\", i, 'tips,', div_scenario, 'model,', data_norm, 'norm')\n",
    "            nn_model = create_nn(len(y_reg_train[0]),\n",
    "                                 int(i), div_scenario=div_scenario)\n",
    "            nn_model.compile(loss=\"mae\", optimizer=Adam(learning_rate=0.001),\n",
    "                             metrics=['mse'])\n",
    "\n",
    "            start = time()\n",
    "            history = nn_model.fit(np.expand_dims(X_train, axis=2),\n",
    "                                   np.expand_dims(y_reg_train, axis=2),\n",
    "                                   batch_size=128, epochs=1000, validation_split=0.1,\n",
    "                                   callbacks=[callback], verbose=0)\n",
    "            elapsed_time = time()-start\n",
    "            print('Elapsed time', elapsed_time)\n",
    "\n",
    "            save_path = out_folder_path + 'reg/' + div_scenario + '/'\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            save_path +=  i + \"_regression\" + data_norm + '_'\n",
    "\n",
    "            nn_model.save(save_path + \"model.keras\")\n",
    "            with open(save_path + \"history.pkl\", 'wb') as f:\n",
    "                    pickle.dump(history.history, f)\n",
    "            with open(save_path + \"model_data.pkl\", 'wb') as f:\n",
    "                    pickle.dump([nn_model.count_params(), elapsed_time], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
